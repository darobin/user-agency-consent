<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>User Agency, Not User Consent</title>
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@robinberjon">
    <meta name="twitter:creator" content="@robinberjon">
    <meta name="twitter:title" property="og:title" content="User Agency, Not User Consent">
    <meta name="twitter:description" property="og:description" content="My position statement for the W3C Workshop on Permissions and User Consent">
    <meta name="twitter:image" property="og:image" content="https://darobin.github.io/user-agency-consent/google-forced-consent.png">
    <meta name="twitter:url" property="og:url" content="https://darobin.github.io/user-agency-consent/">
    <meta property="og:site_name" content="Robin Berjon">
    <meta property="og:type" content="blog">
    <meta property="og:locale" content="en_UK">
    <meta name="theme-color" content="#000">
    <style>
      html, body {
        margin: 0;
        padding: 0;
        background: #fff;
      }
      main {
        margin: 0 auto;
        max-width: 21cm;
        font-family: Franklin, Arial, sans-serif;
        line-height: 1.4;
      }
      header {
        margin-bottom: 3em;
        line-height: initial;
      }
      h1 {
        font-family: Cheltenham, Georgia, serif;
        font-weight: normal;
        font-size: 3em;
        margin: 3em 0 0 0;
      }
      p.meta {
        text-align: right;
      }
      a {
        color: #2fa6fe;
        text-decoration: none;
        background: linear-gradient(0deg, #fff100 0%, #fff100 10%, transparent 11%);
      }
      a:hover {
        background: linear-gradient(0deg, #fff100 0%, #fff100 10%, transparent 31%);
      }
      img {
        max-width: 100%;
      }
      figure {
        text-align: center;
        background: #d3e1e6;
        padding: 10px;
        margin-left: 0;
        margin-right: 0;
      }
      figcaption {
        text-align: left;
        background: #fff;
        margin: 0 -8px -8px -8px;
        padding: 10px;
        font-style: italic;
      }
      figure > img {
        margin-bottom: 10px;
        border: 2px solid #656061;
      }
      li {
        margin: 1em 0;
      }
    </style>
  </head>
  <body>
    <main>
      <header>
        <h1>User Agency, Not User Consent</h1>
        <p class="meta">
          Robin Berjon,
          <a href="mailto:robin.berjon@nytimes.com">robin.berjon@nytimes.com</a>,
          <a href="https://berjon.com/">https://berjon.com/</a>,
          <a href="https://twitter.com/robinberjon">@robinberjon</a>.
        </p>
      </header>
      <p>
        Consent is increasingly seen as the primary basis upon which to process personal data, in
        much the same way that it was long considered to be an acceptable foundation atop which a
        security model could grant an application access to elevated privileges. It was by and large
        a dreadful approach to security, it is hardly any better for privacy.
      </p>
      <figure>
        <img src="activex.jpeg" width="341" height="134" alt="ActiveX security prompt">
        <img src="google-forced-consent.png" width="636" height="456" alt="Google privacy prompt">
        <figcaption>Twenty years of progress in putting users first on the Web</figcaption>
      </figure>
      <p>
        Relying on consent to the processing of personal data suffers from numerous issues, amongst
        which:
      </p>
      <ul>
        <li>
          It leads to consent fatigue such that users — even when educated to the
          underlying issues — will eventually give up and simply accept.
        </li>
        <li>
          It strongly incentivises dark UX patterns from the party expect to garner consent. This
          has led to a race to define increasingly precise guidelines as to what constitutes fair
          and informed consent (the WP29
          “<a href="http://ec.europa.eu/newsroom/article29/item-detail.cfm?item_id=623051">Guidelines
          On Consent</a>” run to 31 pages with dozens of footnotes referring to other sources for
          further detail). The likelihood that regulators can beat thousands of designers working
          to defeat user protections in this race is low.
        </li>
        <li>
          It is grounded in a simplistic vision of personal data processing. In today’s Web economy,
          even a relatively simple service will be tied up in a know of personal data processing
          that is by far too complex to convey to a user within a single dialog (no matter how often
          WP29 calls for creativity in this domain), and users do not have the time (or desire) to
          make such decisions several times a day.
        </li>
        <li>
          It puts the onus of enforcement and decision on the user, representing an abdication of
          responsibility from service providers and user agents. If the option for individual
          controls over privacy is desirable, the broad application of consent is inherently a
          surrender of privacy by design and by default.
        </li>
        <li>
          While the literature describes cases in which after-the-fact consent is meaningful, and in
          some less-invasive cases implied consent is acceptable, overall consent tends to imply
          modal interfaces. These, in turn, inherently lead to fatigue and automatic bypassing. It
          could be argued that consent is structurally problematic.
        </li>
        <li>
          Overally, when consent is relied upon excessively it becomes toxic for privacy both at the
          individual and collective levels.
        </li>
      </ul>
      <p>
        This is not to say that consent should never be used when processing personal data, there
        are situations in which it is the best option — when it is rare enough to catch the user’s
        attention, typically when sensitive personal data or potentially harmful processing are
        involved.
      </p>
      <p>
        Ideally, the processing of personal data should involve:
      </p>
      <!-- make this not a list, just a few short items -->
      <ul>
        <li>
          <strong>Agency</strong>: personal data sharing should only happen as a result of direct
          user action. There should be room for responsible interpretation, for instance if a user
          instructs their browser to visit a site then they need not approve every last piece of
          personal data that the browser provides that site with (but sharing with third parties is
          evidently not part of the user’s instruction and needs a legal basis of its own for the
          browser to act under).
        </li>
        <li>
          <strong>Responsibility</strong>: the data controller should
        </li>
        <li>
          <strong>Asynchrony</strong>:
        </li>
        <li>
          <strong>Auditability</strong>:
        </li>
      </ul>
    </main>
    <!--
      XXX
      - requirements
        - agency: user action
        - fiduciary: responsibility to decide the right processing must fall to the controller
        - asynchronous: no modality, can review later
        - automatically auditable: it should be possible to get a
      - agency > consent (for security, but also for privacy)
      - third-party cookies issue as a case (and mention GDPR violation as an open question, but
        with list of articles violatied)
      ## Outline
      * Machine-readable provenance
        * What is the MVP?
        * How easily can we deploy simple systems that detail provenance?
        * How can they be turned into effective reports?
      * Unlike security, privacy can lend itself more to asynchronous processing
        * With rights of erasure, privacy can (assuming no bad actors, which aren't the primary
          threat) be recuperated after the fact.
        * Strong declarative provenance can be audited
        * There can be user-level audits: what is the transitive tree of data sharing for a given
          system you interact with?
      * Transparency in personal data processing can be key and regulatorily enforced. People only
        need to care once in a while, and a small number of caring people can lead to enforcement
        for all. This is a vastly superior to the individualistic model behind consent.
      * This leads to a reinforcement of legitimate interest as a basis, given stronger transparency
      * Where to add:
        * The 3P cookie issue as a violation (try to mention it in there somewhere)
    -->
  </body>
</html>
