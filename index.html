<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>User Agency, Not User Consent</title>
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@robinberjon">
    <meta name="twitter:creator" content="@robinberjon">
    <meta name="twitter:title" property="og:title" content="User Agency, Not User Consent">
    <meta name="twitter:description" property="og:description" content="My position statement for the W3C Workshop on Permissions and User Consent">
    <meta name="twitter:image" property="og:image" content="https://darobin.github.io/user-agency-consent/google-forced-consent.png">
    <meta name="twitter:url" property="og:url" content="https://darobin.github.io/user-agency-consent/">
    <meta property="og:site_name" content="Robin Berjon">
    <meta property="og:type" content="blog">
    <meta property="og:locale" content="en_UK">
    <meta name="theme-color" content="#000">
    <style>
      html, body {
        margin: 0;
        padding: 0;
        background: #fff;
      }
      main {
        margin: 0 auto;
        max-width: 21cm;
        font-family: Franklin, Arial, sans-serif;
        line-height: 1.4;
      }
      header {
        margin-bottom: 3em;
        line-height: initial;
      }
      h1, h2 {
        font-family: Cheltenham, Georgia, serif;
        font-weight: normal;
        font-size: 3em;
        margin: 3em 0 0 0;
      }
      h1 {
        font-size: 3em;
        margin: 3em 0 0 0;
      }
      h2 {
        font-size: 2em;
        margin: 2em 0 0 0;
      }
      p.meta {
        text-align: right;
      }
      a {
        color: #2fa6fe;
        text-decoration: none;
        background: linear-gradient(0deg, #fff100 0%, #fff100 10%, transparent 11%);
      }
      a:hover {
        background: linear-gradient(0deg, #fff100 0%, #fff100 10%, transparent 31%);
      }
      img {
        max-width: 100%;
      }
      figure {
        text-align: center;
        background: #d3e1e6;
        padding: 10px;
        margin-left: 0;
        margin-right: 0;
      }
      figcaption {
        text-align: left;
        background: #fff;
        margin: 0 -8px -8px -8px;
        padding: 10px;
        font-style: italic;
      }
      figure > img {
        margin-bottom: 10px;
        border: 2px solid #656061;
      }
      li {
        margin: 1em 0;
      }
    </style>
  </head>
  <body>
    <main>
      <header>
        <h1>User Agency, Not User Consent</h1>
        <p class="meta">
          Robin Berjon,
          <a href="mailto:robin.berjon@nytimes.com">robin.berjon@nytimes.com</a>,
          <a href="https://berjon.com/">https://berjon.com/</a>,
          <a href="https://twitter.com/robinberjon">@robinberjon</a>.
        </p>
      </header>
      <p>
        This paper seeks less to detail an exact solution and more to outline a genuine problem and
        some potential requirements to address it.
      </p>
      <section>
        <h2>Consent Is Toxic For Privacy</h2>
        <p>
          Consent is increasingly seen as the primary basis upon which to process personal data, in
          much the same way that it was long considered to be an acceptable foundation atop which a
          security model could grant an application access to elevated privileges. It was by and large
          a dreadful approach to security, it is hardly any better for privacy.
        </p>
        <figure>
          <img src="activex.jpeg" width="341" height="134" alt="ActiveX security prompt">
          <img src="google-forced-consent.png" width="636" height="456" alt="Google privacy prompt">
          <figcaption>Twenty years of progress in putting users first on the Web</figcaption>
        </figure>
        <p>
          Relying on consent to the processing of personal data suffers from numerous issues, amongst
          which:
        </p>
        <ul>
          <li>
            It leads to consent fatigue such that users — even when educated to the
            underlying issues — will eventually give up and simply accept.
          </li>
          <li>
            It strongly incentivises dark UX patterns from the party expect to garner consent. This
            has led to a race to define increasingly precise guidelines as to what constitutes fair
            and informed consent (the WP29
            “<a href="http://ec.europa.eu/newsroom/article29/item-detail.cfm?item_id=623051">Guidelines
            On Consent</a>” run to 31 pages with dozens of footnotes referring to other sources for
            further detail). The likelihood that regulators can beat thousands of designers working
            to defeat user protections in this race is low.
          </li>
          <li>
            It is grounded in a simplistic vision of personal data processing. In today’s Web economy,
            even a relatively simple service will be tied up in a know of personal data processing
            that is by far too complex to convey to a user within a single dialog (no matter how often
            WP29 calls for creativity in this domain), and users do not have the time (or desire) to
            make such decisions several times a day.
          </li>
          <li>
            It puts the onus of enforcement and decision on the user, representing an abdication of
            responsibility from service providers and user agents. If the option for individual
            controls over privacy is desirable, the broad application of consent is inherently a
            surrender of privacy by design and by default.
          </li>
          <li>
            While the literature describes cases in which after-the-fact consent is meaningful, and in
            some less-invasive cases implied consent is acceptable, overall consent tends to imply
            modal interfaces. These, in turn, inherently lead to fatigue and automatic bypassing. It
            could be argued that consent is structurally problematic.
          </li>
          <li>
            Overally, when consent is relied upon excessively it becomes toxic for privacy both at the
            individual and collective levels.
          </li>
        </ul>
        <p>
          This is not to say that consent should never be used when processing personal data, there
          are situations in which it is the best option — when it is rare enough to catch the user’s
          attention, typically when sensitive personal data or potentially harmful processing are
          involved.
        </p>
      </section>
      <section>
        <h2>Traceability &amp; Provenance</h2>
        <p>
          More so than security, privacy can benefit from curative approaches in addition to — or at
          times instead of — preventative ones. With rights of erasure, privacy can (assuming no
          illegal actors, which aren't the primary threat) be recuperated after the fact.
        </p>
        <p>
          This opens up avenues in which privacy would not be handled synchronously — a requirement
          that is at the root of many of the problems with consent — but through after-the-fact
          cleaning up (either by the user, or by services the user could rely upon).
        </p>
        <p>
          Regulation-backed rules requiring user agents to track which data they share, and require
          services to provide machine-readable traceability of which other parties they then share
          data with would enable the production of the transitive tree of data sharing for a given
          user, would expose the full breadth of sharing, and thereby would enable cleanup sessions
          in which data erasure requests would be automatically dispatched to most if not all of
          those third parties, inclusive of data shared outside of direct oversight by the user.
        </p>
        <p>
          I am deliberately not jumping into solutions (though many suggestions have been made, from
          reliance on <code>.well-known</code> descriptions of sharing and provenance to new session mechanisms
          replacing cookies). The point is to replace modal, synchrono us consent with amodal,
          asynchronous agency over a user's involuntary data footprint while enabling auditability
          of the data sharing by trustworthy third parties.
        </p>
      </section>
    </main>
  </body>
</html>
